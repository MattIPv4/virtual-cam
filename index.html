<html>
<head>
    <style>
        html,
        body {
            margin: 0;
            padding: 0;
            height: 100vh;
            overflow: hidden;
            background: rgba(0, 0, 0, 1);
        }

        .overlay {
            position: fixed;
            top: 0;
            bottom: 0;
            left: 0;
            right: 0;
            max-height: 100%;
            max-width: 100%;
            background: rgba(0, 0, 0, 0.5);
        }

        html,
        body,
        .overlay {
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }
    </style>
</head>
<body>
<script>
    const { join } = require('path');
    const { loadImage, loadNets, detect, warp } = require('./warp');

    // Some stuff we need to store
    const FPS = 60;
    let frames = 0; // Number of frames the app has generated
    let latency = 0; // Average latency for generating a frame
    let state; // The state of the application
    let device; // The media device ID to use
    let avatarData; // Face track data for avatar
    let applyWarp = false, applyMirror = false; // Output effect toggles

    // Source image
    const AVATAR = loadImage(join(__dirname, 'avatar.png'));

    // Hidden video element for webcam stream
    const video = document.createElement('video');

    // Output canvas
    const canvas = document.createElement('canvas');
    canvas.style.height = '100%';
    canvas.style.width = '100%';
    canvas.style.objectFit = 'contain';
    document.body.appendChild(canvas);

    // Overlay for settings
    const overlay = document.createElement('div');
    overlay.className = 'overlay';
    document.body.appendChild(overlay);

    const createStream = () => {
        // Get the webcam feed to a shadow video elm
        navigator.mediaDevices.getUserMedia({ audio: false, video: { deviceId: device } }).then(stream => {
            video.srcObject = stream;
            video.onloadedmetadata = () => video.play();
        }).catch(err => console.log(err));
    };

    const processFrame = async () => {
        // Whilst in select device state, preview avatar detection
        if (state === 'select-device' && avatarData) {
            canvas.width = AVATAR.width
            canvas.height = AVATAR.height
            const canvasCtx = canvas.getContext('2d');
            canvasCtx.drawImage(AVATAR, 0, 0, AVATAR.width, AVATAR.height);
            canvasCtx.strokeStyle = '#f0f';
            canvasCtx.lineWidth = 5;
            canvasCtx.strokeRect(avatarData.x, avatarData.y, avatarData.width, avatarData.height);
            for (const point of avatarData.points) {
                canvasCtx.beginPath();
                canvasCtx.arc(...point, 5, 0, 2 * Math.PI);
                canvasCtx.fillStyle = '#0ff';
                canvasCtx.fill();
            }
            return
        }

        // Only process video frame if video is active
        if (video.videoHeight === 0 || video.videoWidth === 0) return;

        // Track the start time for the frame render
        const start = Date.now();

        // Get the frame
        const frame = document.createElement('canvas');
        frame.width = video.videoWidth;
        frame.height = video.videoHeight;
        const ctx = frame.getContext('2d');
        ctx.drawImage(video, 0, 0, frame.width, frame.height);

        // Run face detection on it
        const detectionData = await detect(frame);
        if (detectionData.success !== true) return;

        // Display the detection data
        ctx.strokeStyle = '#f0f';
        ctx.lineWidth = 5;
        ctx.strokeRect(detectionData.x, detectionData.y, detectionData.width, detectionData.height);
        for (const point of detectionData.points) {
            ctx.beginPath();
            ctx.arc(...point, 5, 0, 2 * Math.PI);
            ctx.fillStyle = '#0ff';
            ctx.fill();
        }

        // Perform the warp
        const { overlay, xScale, yScale } = warp(avatarData, detectionData, AVATAR, applyWarp);

        // Draw onto the frame (aligning the face boxes)
        const x = detectionData.x - (avatarData.x * xScale);
        const y = detectionData.y - (avatarData.y * yScale);
        ctx.drawImage(overlay, x, y, overlay.width, overlay.height);
        ctx.strokeStyle = '#ff0';
        ctx.lineWidth = 5;
        ctx.strokeRect(x, y, overlay.width, overlay.height);

        // Display
        canvas.width = frame.width
        canvas.height = frame.height
        const canvasCtx = canvas.getContext('2d');
        canvasCtx.save();
        if (applyMirror) {
            canvasCtx.translate(canvas.width, 0);
            canvasCtx.scale(-1, 1);
        }
        canvasCtx.drawImage(frame, 0, 0, canvas.width, canvas.height);
        canvasCtx.restore();

        // Update the rolling latency
        latency = ((latency * frames) + (Date.now() - start)) / (frames + 1);
        frames++;
        console.log(latency);
        console.log(frames);
    }

    // Get frames for the canvas
    setInterval(processFrame, 1000 / FPS);

    const main = async () => {
        // Load the nets first
        await loadNets();

        // Process the avatar
        avatarData = await detect(AVATAR, false);

        // Listen for spacebar to toggle state
        window.addEventListener('keyup', event => {
            console.log(event.code);

            if (event.code === 'KeyA') {
                applyWarp = !applyWarp;
            }

            if (event.code === 'KeyF') {
                applyMirror = !applyMirror;
            }

            // Enter triggers device menu
            if (event.code === 'Enter') {
                state = 'select-device';
                overlay.style.display = '';
            }
        }, true);

        // Get all the media devices available
        state = 'select-device';
        const devices = (await navigator.mediaDevices.enumerateDevices())
            .filter(device => device.kind === 'videoinput');

        // Generate a select
        const select = document.createElement('select');
        for (const device of devices) {
            const opt = document.createElement('option');
            opt.text = device.label;
            opt.value = device.deviceId;
            select.options.add(opt);
        }
        overlay.appendChild(select);

        // Add the button
        const button = document.createElement('button');
        button.textContent = 'Set webcam';
        button.addEventListener('click', (event) => {
            event.preventDefault();
            device = select.value;
            state = 'active';
            overlay.style.display = 'none';
            createStream();
        });
        overlay.appendChild(button);
    };

    main();
</script>
</body>
</html>
